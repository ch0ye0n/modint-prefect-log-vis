timestamp,level,flow_run_id,task_run_id,message
2025-11-04 07:54:50.779277+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,,Worker 'KubernetesWorker 2eef4ca3-1a3c-4874-ae0a-cd98fb643060' submitting flow run '0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5'
2025-11-04 07:54:50.987418+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,,Creating Kubernetes job...
2025-11-04 07:54:51.311463+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,,Completed submission of flow run '0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5'
2025-11-04 07:54:57.777675+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,,Opening process...
2025-11-04 07:55:00.548075+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,, > Running git_clone step...
2025-11-04 07:55:09.290363+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,,Beginning flow run 'zeta5-iximche' for flow 'run-modint-flow'
2025-11-04 07:55:09.401770+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d48f-717b-86c7-c82784d4f40a,This job ID will be used - modint-prefect-zeta5-iximche-1
2025-11-04 07:55:09.444752+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d48f-717b-86c7-c82784d4f40a,Finished in state Completed()
2025-11-04 07:55:10.043523+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d508-70b3-ac8f-179c6518e1d4,Finished in state Completed()
2025-11-04 07:55:10.052824+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d508-7f07-85c1-dec272bb9f6a,Finished in state Completed()
2025-11-04 07:55:10.161527+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50e-76fd-a8e3-7216f57891c4,{'scene_path': '/nas/Projects/C-BIZ01A/GeoImage_Samples/Wyvern/'}
2025-11-04 07:55:10.257731+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d7fd-7f82-93e8-afa82818a251,Finished in state Completed()
2025-11-04 07:55:10.411214+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50c-77ce-9a75-aa3c246fd0dd,"spawn /app/modint_prefect/utils/scheduler config
[?25l[2K[1m[32mâœ”[0m [1mServer Connection: [0m[1m:[0m â–ˆ
[Jspawn /app/modint_prefect/utils/scheduler login
[?25l[2K[1m[31mâœ—[0m [1mLogin id: [0m[1m:[0m â–ˆ
[J [Jd [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dâ–ˆ
d [J [Jl [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlâ–ˆ
l [J [Jk [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlkâ–ˆ
k [J [J- [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlk-â–ˆ
- [J [Jb [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlk-bâ–ˆ
b [J [Jo [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlk-boâ–ˆ
o [J [Jt [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlk-botâ–ˆ
t [J [J [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlk-botâ–ˆ
[1A[2K[2K[2mLogin id: [0m[2m:[0m dlk-bot
[?25h[?25l[2K[1m[31mâœ—[0m [1mPassword: [0m[1m:[0m â–ˆ
[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m *â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m **â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m ***â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m ****â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m *****â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m ******â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m *******â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m ********â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m *********â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m **********â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m ***********â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m ************â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m *************â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m **************â–ˆ
*[J [J [J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m **************â–ˆ
[1A[2K[2K[2mPassword: [0m[2m:[0m **************
[?25hLogin succeed: dlk-bot@si-analytics.ai
Login successful
"
2025-11-04 07:55:10.417516+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50c-77ce-9a75-aa3c246fd0dd,"Running this command in scheduler... /app/modint_prefect/utils/scheduler run --name modint-prefect-zeta5-iximche-1 --cpus 2 --memory 64Gi --gpus 1 --node a10-101,a40-102,a100-101,a6000-101,a6000-102,a6000-103,v100-101,v100-202 harbor.sia-service.kr/research/weaver:modint-v0.1.1-20250717.28 -- python3 tools/infer.py --host dev-cluster.sia-service.kr --port 31438 --job_id modint-prefect-zeta5-iximche-1 --output_path /nas/Projects/C-BIZ01A/GeoImage_Samples/Wyvern/Results/ --run-id c2b3f5e59a184645a157d7b230809321"
2025-11-04 07:55:13.647385+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50c-77ce-9a75-aa3c246fd0dd,
2025-11-04 07:55:13.655317+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50c-77ce-9a75-aa3c246fd0dd,Finished in state Completed()
2025-11-04 07:56:16.627378+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50d-7691-af6f-018f464e5a3e,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '55s', 'node': 'a100-101', 'gpus': '1', 'ports': ''}"
2025-11-04 07:57:26.388731+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50d-7691-af6f-018f464e5a3e,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '1m', 'node': 'a100-101', 'gpus': '1', 'ports': ''}"
2025-11-04 07:58:32.014992+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50d-7691-af6f-018f464e5a3e,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '3m', 'node': 'a100-101', 'gpus': '1', 'ports': ''}"
2025-11-04 07:59:38.256892+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50d-7691-af6f-018f464e5a3e,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '4m', 'node': 'a100-101', 'gpus': '1', 'ports': ''}"
2025-11-04 08:00:42.829671+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50d-7691-af6f-018f464e5a3e,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '5m', 'node': 'a100-101', 'gpus': '1', 'ports': ''}"
2025-11-04 08:01:45.517949+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50d-7691-af6f-018f464e5a3e,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '6m', 'node': 'a100-101', 'gpus': '1', 'ports': ''}"
2025-11-04 08:02:10.535260+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50e-76fd-a8e3-7216f57891c4,Progress: 25.0 percent
2025-11-04 08:02:40.570959+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50e-76fd-a8e3-7216f57891c4,Progress: 91.66666666666666 percent
2025-11-04 08:02:51.355634+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50d-7691-af6f-018f464e5a3e,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '7m', 'node': 'a100-101', 'gpus': '1', 'ports': ''}"
2025-11-04 08:03:10.605974+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50e-76fd-a8e3-7216f57891c4,None
2025-11-04 08:03:10.611147+00:00,40,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50e-76fd-a8e3-7216f57891c4,Inference was failed. See the logs for detail.
2025-11-04 08:03:10.613375+00:00,40,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50e-76fd-a8e3-7216f57891c4,"Task run failed with exception: InferenceFailError() - No retries configured for this task.
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 857, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 1487, in run_task_sync
    engine.call_task_fn(txn)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 874, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 135, in run_check_inference_status_redis
    raise InferenceFailError
modint_prefect.configs.InferenceFailError"
2025-11-04 08:03:10.628701+00:00,40,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50e-76fd-a8e3-7216f57891c4,Finished in state Failed('Task run encountered an exception InferenceFailError: ')
2025-11-04 08:03:55.196525+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50d-7691-af6f-018f464e5a3e,Scheduler status succeeded!
2025-11-04 08:03:55.198954+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50d-7691-af6f-018f464e5a3e,"{'user': 'dlk-bot', 'status': 'Succeeded', 'reason': 'Completed', 'age': '8m', 'node': 'a100-101', 'gpus': '', 'ports': ''}"
2025-11-04 08:03:55.200968+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50d-7691-af6f-018f464e5a3e,"['/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers', '  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)', '\rDownloading artifacts:   0%|          | 0/2 [00:00<?, ?it/s]\rDownloading artifacts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 46.68it/s]\rDownloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.38s/it]\rDownloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.38s/it]\rDownloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.38s/it]', 'load checkpoint from local path: /tmp/tmpoguddxvs/checkpoint/model_final.pth', 'The model and loaded state dict do not match exactly', '', 'unexpected key in source state_dict: perceptual_loss.vgg.mean, perceptual_loss.vgg.std, perceptual_loss.vgg.vgg_layers.0.weight, perceptual_loss.vgg.vgg_layers.0.bias, perceptual_loss.vgg.vgg_layers.2.weight, perceptual_loss.vgg.vgg_layers.2.bias, perceptual_loss.vgg.vgg_layers.5.weight, perceptual_loss.vgg.vgg_layers.5.bias, perceptual_loss.vgg.vgg_layers.7.weight, perceptual_loss.vgg.vgg_layers.7.bias, perceptual_loss.vgg.vgg_layers.10.weight, perceptual_loss.vgg.vgg_layers.10.bias, perceptual_loss.vgg.vgg_layers.12.weight, perceptual_loss.vgg.vgg_layers.12.bias, perceptual_loss.vgg.vgg_layers.14.weight, perceptual_loss.vgg.vgg_layers.14.bias, perceptual_loss.vgg.vgg_layers.16.weight, perceptual_loss.vgg.vgg_layers.16.bias, perceptual_loss.vgg.vgg_layers.19.weight, perceptual_loss.vgg.vgg_layers.19.bias, perceptual_loss.vgg.vgg_layers.21.weight, perceptual_loss.vgg.vgg_layers.21.bias, perceptual_loss.vgg.vgg_layers.23.weight, perceptual_loss.vgg.vgg_layers.23.bias, perceptual_loss.vgg.vgg_layers.25.weight, perceptual_loss.vgg.vgg_layers.25.bias, perceptual_loss.vgg.vgg_layers.28.weight, perceptual_loss.vgg.vgg_layers.28.bias, perceptual_loss.vgg.vgg_layers.30.weight, perceptual_loss.vgg.vgg_layers.30.bias, perceptual_loss.vgg.vgg_layers.32.weight, perceptual_loss.vgg.vgg_layers.32.bias, perceptual_loss.vgg.vgg_layers.34.weight, perceptual_loss.vgg.vgg_layers.34.bias', '', '/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers', '  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)', '/usr/local/lib/python3.10/dist-packages/mmedit/utils/setup_env.py:17: UserWarning: Multi-processing start method `fork` is different from the previous setting `spawn`.It will be force set to `fork`. You can change this behavior by changing `mp_start_method` in your config.', '  warnings.warn(', '[2025-11-04 08:01:52] [INFO] [SE Runner - 0] - start load ddp model', 'load checkpoint from local path: /tmp/tmpoguddxvs/checkpoint/model_final.pth', 'The model and loaded state dict do not match exactly', '', 'unexpected key in source state_dict: perceptual_loss.vgg.mean, perceptual_loss.vgg.std, perceptual_loss.vgg.vgg_layers.0.weight, perceptual_loss.vgg.vgg_layers.0.bias, perceptual_loss.vgg.vgg_layers.2.weight, perceptual_loss.vgg.vgg_layers.2.bias, perceptual_loss.vgg.vgg_layers.5.weight, perceptual_loss.vgg.vgg_layers.5.bias, perceptual_loss.vgg.vgg_layers.7.weight, perceptual_loss.vgg.vgg_layers.7.bias, perceptual_loss.vgg.vgg_layers.10.weight, perceptual_loss.vgg.vgg_layers.10.bias, perceptual_loss.vgg.vgg_layers.12.weight, perceptual_loss.vgg.vgg_layers.12.bias, perceptual_loss.vgg.vgg_layers.14.weight, perceptual_loss.vgg.vgg_layers.14.bias, perceptual_loss.vgg.vgg_layers.16.weight, perceptual_loss.vgg.vgg_layers.16.bias, perceptual_loss.vgg.vgg_layers.19.weight, perceptual_loss.vgg.vgg_layers.19.bias, perceptual_loss.vgg.vgg_layers.21.weight, perceptual_loss.vgg.vgg_layers.21.bias, perceptual_loss.vgg.vgg_layers.23.weight, perceptual_loss.vgg.vgg_layers.23.bias, perceptual_loss.vgg.vgg_layers.25.weight, perceptual_loss.vgg.vgg_layers.25.bias, perceptual_loss.vgg.vgg_layers.28.weight, perceptual_loss.vgg.vgg_layers.28.bias, perceptual_loss.vgg.vgg_layers.30.weight, perceptual_loss.vgg.vgg_layers.30.bias, perceptual_loss.vgg.vgg_layers.32.weight, perceptual_loss.vgg.vgg_layers.32.bias, perceptual_loss.vgg.vgg_layers.34.weight, perceptual_loss.vgg.vgg_layers.34.bias', '', '[2025-11-04 08:01:55] [INFO] [SE Runner - 0] - end load ddp model', '[2025-11-04 08:01:55] [INFO] [SE Runner - 0] - start build dataloader', '[2025-11-04 08:01:57] [INFO] [SE Runner - 0] - end build dataloader', '[2025-11-04 08:01:57] [INFO] [SE Runner - 0] - start create memory map', '[2025-11-04 08:01:57] [INFO] [SE Runner - 0] - end create memory map', '[                                                  ] 0/12, elapsed: 0s, ETA:\r[>>                                ] 1/12, 0.2 task/s, elapsed: 5s, ETA:    54s\r[>>>>>                             ] 2/12, 0.2 task/s, elapsed: 8s, ETA:    42s\r[>>>>>>>>                         ] 3/12, 0.3 task/s, elapsed: 12s, ETA:    36s\r[>>>>>>>>>>>                      ] 4/12, 0.3 task/s, elapsed: 16s, ETA:    31s\r[>>>>>>>>>>>>>                    ] 5/12, 0.3 task/s, elapsed: 19s, ETA:    27s\r[>>>>>>>>>>>>>>>>                 ] 6/12, 0.3 task/s, elapsed: 23s, ETA:    23s\r[>>>>>>>>>>>>>>>>>>>              ] 7/12, 0.3 task/s, elapsed: 26s, ETA:    19s\r[>>>>>>>>>>>>>>>>>>>>>>           ] 8/12, 0.3 task/s, elapsed: 30s, ETA:    15s\r[>>>>>>>>>>>>>>>>>>>>>>>>         ] 9/12, 0.3 task/s, elapsed: 33s, ETA:    11s\r[>>>>>>>>>>>>>>>>>>>>>>>>>>      ] 10/12, 0.3 task/s, elapsed: 37s, ETA:     7s\r[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 11/12, 0.3 task/s, elapsed: 41s, ETA:     4s\r[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 12/12, 0.3 task/s, elapsed: 44s, ETA:     0s', '/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers', '  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)', '/usr/local/lib/python3.10/dist-packages/mmedit/utils/setup_env.py:17: UserWarning: Multi-processing start method `fork` is different from the previous setting `spawn`.It will be force set to `fork`. You can change this behavior by changing `mp_start_method` in your config.', '  warnings.warn(', '[2025-11-04 08:03:01] [INFO] [SE Runner - 0] - start load ddp model', 'load checkpoint from local path: /tmp/tmpoguddxvs/checkpoint/model_final.pth', 'The model and loaded state dict do not match exactly', '', 'unexpected key in source state_dict: perceptual_loss.vgg.mean, perceptual_loss.vgg.std, perceptual_loss.vgg.vgg_layers.0.weight, perceptual_loss.vgg.vgg_layers.0.bias, perceptual_loss.vgg.vgg_layers.2.weight, perceptual_loss.vgg.vgg_layers.2.bias, perceptual_loss.vgg.vgg_layers.5.weight, perceptual_loss.vgg.vgg_layers.5.bias, perceptual_loss.vgg.vgg_layers.7.weight, perceptual_loss.vgg.vgg_layers.7.bias, perceptual_loss.vgg.vgg_layers.10.weight, perceptual_loss.vgg.vgg_layers.10.bias, perceptual_loss.vgg.vgg_layers.12.weight, perceptual_loss.vgg.vgg_layers.12.bias, perceptual_loss.vgg.vgg_layers.14.weight, perceptual_loss.vgg.vgg_layers.14.bias, perceptual_loss.vgg.vgg_layers.16.weight, perceptual_loss.vgg.vgg_layers.16.bias, perceptual_loss.vgg.vgg_layers.19.weight, perceptual_loss.vgg.vgg_layers.19.bias, perceptual_loss.vgg.vgg_layers.21.weight, perceptual_loss.vgg.vgg_layers.21.bias, perceptual_loss.vgg.vgg_layers.23.weight, perceptual_loss.vgg.vgg_layers.23.bias, perceptual_loss.vgg.vgg_layers.25.weight, perceptual_loss.vgg.vgg_layers.25.bias, perceptual_loss.vgg.vgg_layers.28.weight, perceptual_loss.vgg.vgg_layers.28.bias, perceptual_loss.vgg.vgg_layers.30.weight, perceptual_loss.vgg.vgg_layers.30.bias, perceptual_loss.vgg.vgg_layers.32.weight, perceptual_loss.vgg.vgg_layers.32.bias, perceptual_loss.vgg.vgg_layers.34.weight, perceptual_loss.vgg.vgg_layers.34.bias', '', '[2025-11-04 08:03:03] [INFO] [SE Runner - 0] - end load ddp model', '[2025-11-04 08:03:03] [INFO] [SE Runner - 0] - start build dataloader', '[2025-11-04 08:03:05] [INFO] [SE Runner - 0] - end build dataloader', '[2025-11-04 08:03:05] [INFO] [SE Runner - 0] - start create memory map', '[2025-11-04 08:03:05] [INFO] [SE Runner - 0] - end create memory map', '2025-11-04 08:03:07.114 | ERROR    | se:inference:434 - An exception occurred:', 'Traceback (most recent call last):', '  File ""/weaver/se.py"", line 397, in inference', '    mp.spawn(', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 246, in spawn', '    return start_processes(fn, args, nprocs, join, daemon, start_method=""spawn"")', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 202, in start_processes', '    while not context.join():', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 163, in join', '    raise ProcessRaisedException(msg, error_index, failed_process.pid)', 'torch.multiprocessing.spawn.ProcessRaisedException: ', '', '-- Process 0 terminated with the following error:', 'Traceback (most recent call last):', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 74, in _wrap', '    fn(i, *args)', '  File ""/weaver/se.py"", line 329, in mp_inference', '    results = self.predict(data, model)', '  File ""/weaver/se.py"", line 154, in predict', '    result = model(**batch, test_mode=True)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py"", line 1519, in forward', '    else self._run_ddp_forward(*inputs, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py"", line 1355, in _run_ddp_forward', '    return self.module(*inputs, **kwargs)  # type: ignore[index]', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/selfsup/module/mmcv/mmcv/runner/fp16_utils.py"", line 109, in new_func', '    return old_func(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/mmedit/models/restorers/srgan.py"", line 95, in forward', '    return self.forward_test(lq, gt, **kwargs)', '  File ""/weaver/weaver/models/restorers/real_esrgan.py"", line 275, in forward_test', '    output = _model(lq)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/weaver/weaver/models/backbones/sr_backbones/restormer_net.py"", line 468, in forward', '    inp_enc_level1 = self.patch_embed(inp_img)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/weaver/weaver/models/backbones/sr_backbones/restormer_net.py"", line 241, in forward', '    x = self.proj(x)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py"", line 460, in forward', '    return self._conv_forward(input, self.weight, self.bias)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py"", line 456, in _conv_forward', '    return F.conv2d(input, weight, bias, self.stride,', 'RuntimeError: Given groups=1, weight of size [64, 4, 3, 3], expected input[1, 3, 1000, 1000] to have 4 channels, but got 3 channels instead', '', '', '[                                                  ] 0/12, elapsed: 0s, ETA:\x1b[32m2025-11-04T08:03:07.114580+0000\x1b[0m \x1b[31m\x1b[1mAn exception occurred:', 'Traceback (most recent call last):', '  File ""/weaver/se.py"", line 397, in inference', '    mp.spawn(', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 246, in spawn', '    return start_processes(fn, args, nprocs, join, daemon, start_method=""spawn"")', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 202, in start_processes', '    while not context.join():', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 163, in join', '    raise ProcessRaisedException(msg, error_index, failed_process.pid)', 'torch.multiprocessing.spawn.ProcessRaisedException: ', '', '-- Process 0 terminated with the following error:', 'Traceback (most recent call last):', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 74, in _wrap', '    fn(i, *args)', '  File ""/weaver/se.py"", line 329, in mp_inference', '    results = self.predict(data, model)', '  File ""/weaver/se.py"", line 154, in predict', '    result = model(**batch, test_mode=True)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py"", line 1519, in forward', '    else self._run_ddp_forward(*inputs, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py"", line 1355, in _run_ddp_forward', '    return self.module(*inputs, **kwargs)  # type: ignore[index]', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/selfsup/module/mmcv/mmcv/runner/fp16_utils.py"", line 109, in new_func', '    return old_func(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/mmedit/models/restorers/srgan.py"", line 95, in forward', '    return self.forward_test(lq, gt, **kwargs)', '  File ""/weaver/weaver/models/restorers/real_esrgan.py"", line 275, in forward_test', '    output = _model(lq)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/weaver/weaver/models/backbones/sr_backbones/restormer_net.py"", line 468, in forward', '    inp_enc_level1 = self.patch_embed(inp_img)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/weaver/weaver/models/backbones/sr_backbones/restormer_net.py"", line 241, in forward', '    x = self.proj(x)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py"", line 460, in forward', '    return self._conv_forward(input, self.weight, self.bias)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py"", line 456, in _conv_forward', '    return F.conv2d(input, weight, bias, self.stride,', 'RuntimeError: Given groups=1, weight of size [64, 4, 3, 3], expected input[1, 3, 1000, 1000] to have 4 channels, but got 3 channels instead', '', '\x1b[0m', '']"
2025-11-04 08:03:55.228396+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,019a4ddc-d50d-7691-af6f-018f464e5a3e,Finished in state Completed()
2025-11-04 08:03:55.237966+00:00,40,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,,"Encountered exception during execution: InferenceFailError()
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 782, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 1397, in run_flow_sync
    engine.call_flow_fn()
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 802, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 528, in run_modint_flow
    inference_result = check_inference_status_future.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/futures.py"", line 222, in result
    _result = self._final_state.result(
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/compatibility/async_dispatch.py"", line 94, in wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/prefect/client/schemas/objects.py"", line 366, in result
    return run_coro_as_sync(
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 207, in run_coro_as_sync
    return call.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 365, in result
    return self.future.result(timeout=timeout)
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 192, in result
    return self.__get_result()
  File ""/usr/local/lib/python3.10/concurrent/futures/_base.py"", line 403, in __get_result
    raise self._exception
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 441, in _run_async
    result = await coro
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 188, in coroutine_wrapper
    return await task
  File ""/usr/local/lib/python3.10/site-packages/prefect/states.py"", line 85, in get_state_result
    return await _get_state_result(
  File ""/usr/local/lib/python3.10/site-packages/prefect/states.py"", line 157, in _get_state_result
    raise await get_state_exception(state)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 857, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 1487, in run_task_sync
    engine.call_task_fn(txn)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 874, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 135, in run_check_inference_status_redis
    raise InferenceFailError
modint_prefect.configs.InferenceFailError"
2025-11-04 08:03:55.336781+00:00,20,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,,Finished in state Failed('Flow run encountered an exception: InferenceFailError: ')
2025-11-04 08:03:55.339441+00:00,40,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,,"Engine execution exited with unexpected exception
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 1554, in run_flow
    ret_val = run_flow_sync(**kwargs)
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 1399, in run_flow_sync
    return engine.state if return_type == ""state"" else engine.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 361, in result
    raise self._raised
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 782, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 1397, in run_flow_sync
    engine.call_flow_fn()
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 802, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 528, in run_modint_flow
    inference_result = check_inference_status_future.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/futures.py"", line 222, in result
    _result = self._final_state.result(
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/compatibility/async_dispatch.py"", line 94, in wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/prefect/client/schemas/objects.py"", line 366, in result
    return run_coro_as_sync(
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 207, in run_coro_as_sync
    return call.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 365, in result
    return self.future.result(timeout=timeout)
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 192, in result
    return self.__get_result()
  File ""/usr/local/lib/python3.10/concurrent/futures/_base.py"", line 403, in __get_result
    raise self._exception
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 441, in _run_async
    result = await coro
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 188, in coroutine_wrapper
    return await task
  File ""/usr/local/lib/python3.10/site-packages/prefect/states.py"", line 85, in get_state_result
    return await _get_state_result(
  File ""/usr/local/lib/python3.10/site-packages/prefect/states.py"", line 157, in _get_state_result
    raise await get_state_exception(state)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 857, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 1487, in run_task_sync
    engine.call_task_fn(txn)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 874, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 135, in run_check_inference_status_redis
    raise InferenceFailError
modint_prefect.configs.InferenceFailError"
2025-11-04 08:03:56.196786+00:00,40,0e9c5c8d-5c3c-4de1-98be-d47c7f8b0af5,,Process for flow run 'zeta5-iximche' exited with status code: 1
