timestamp,level,flow_run_id,task_run_id,message
2025-11-04 08:05:56.226909+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,,Worker 'KubernetesWorker 2eef4ca3-1a3c-4874-ae0a-cd98fb643060' submitting flow run '924a1cd4-7c15-4f85-9a39-c5b0652f03dc'
2025-11-04 08:05:56.432647+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,,Creating Kubernetes job...
2025-11-04 08:05:56.825485+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,,Completed submission of flow run '924a1cd4-7c15-4f85-9a39-c5b0652f03dc'
2025-11-04 08:06:03.623058+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,,Opening process...
2025-11-04 08:06:06.353634+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,, > Running git_clone step...
2025-11-04 08:06:11.993380+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,,Beginning flow run 'phi2-betazed-nebula' for flow 'run-modint-flow'
2025-11-04 08:06:12.102666+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f13d-7523-9f66-ad1931ce2a97,This job ID will be used - modint-prefect-phi2-betazed-nebula-1
2025-11-04 08:06:12.105615+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f13d-7523-9f66-ad1931ce2a97,Finished in state Completed()
2025-11-04 08:06:12.659052+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f18b-7bca-a50f-0710591449f5,Finished in state Completed()
2025-11-04 08:06:12.668193+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f18c-775a-a24c-3fcf76f87b32,Finished in state Completed()
2025-11-04 08:06:12.858328+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f44b-7a84-98f4-36dbe232a288,Finished in state Completed()
2025-11-04 08:06:12.862149+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d6-7af3-94ed-f921ac0b9aa5,{'scene_path': '/nas/Projects/C-BIZ01A/GeoImage_Samples/Wyvern/wyvern_dragonette-002_20250613T105800_b6cf8226_8.tif'}
2025-11-04 08:06:13.038230+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d1-7b98-9ad5-f167b88ddffc,"spawn /app/modint_prefect/utils/scheduler config
[?25l[2K[1m[32mâœ”[0m [1mServer Connection: [0m[1m:[0m â–ˆ
[J spawn /app/modint_prefect/utils/scheduler login
[?25l[2K[1m[31mâœ—[0m [1mLogin id: [0m[1m:[0m â–ˆ
[J [Jd [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dâ–ˆ
d [J [Jl [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlâ–ˆ
l [J [Jk [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlkâ–ˆ
k [J [J- [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlk-â–ˆ
- [J [Jb [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlk-bâ–ˆ
b [J [Jo [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlk-boâ–ˆ
o [J [Jt [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlk-botâ–ˆ
t [J [J [J[1A[2K[2K[1m[32mâœ”[0m [1mLogin id: [0m[1m:[0m dlk-botâ–ˆ
 [J[1A[2K[2K[2mLogin id: [0m[2m:[0m dlk-bot
 [?25h[J[?25l[2K[1m[31mâœ—[0m [1mPassword: [0m[1m:[0m â–ˆ
[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m *â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m **â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m ***â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m ****â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m *****â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m ******â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m *******â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m ********â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m *********â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m **********â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m ***********â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m ************â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m *************â–ˆ
*[J [J*[J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m **************â–ˆ
*[J [J [J[1A[2K[2K[1m[32mâœ”[0m [1mPassword: [0m[1m:[0m **************â–ˆ
 [1A[2K[2K[2mPassword: [0m[2m:[0m **************
[?25h[JLogin succeed: dlk-bot@si-analytics.ai
Login successful
"
2025-11-04 08:06:13.044322+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d1-7b98-9ad5-f167b88ddffc,"Running this command in scheduler... /app/modint_prefect/utils/scheduler run --name modint-prefect-phi2-betazed-nebula-1 --cpus 2 --memory 64Gi --gpus 1 --node a10-101,a40-102,a100-101,a6000-101,a6000-102,a6000-103,v100-101,v100-202 harbor.sia-service.kr/research/weaver:modint-v0.1.1-20250717.28 -- python3 tools/infer.py --host dev-cluster.sia-service.kr --port 31438 --job_id modint-prefect-phi2-betazed-nebula-1 --output_path /nas/Projects/C-BIZ01A/GeoImage_Samples/Wyvern/Results/wyvern_dragonette-002_20250613T105800_b6cf8226_8.tif --run-id c2b3f5e59a184645a157d7b230809321"
2025-11-04 08:06:13.314849+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d1-7b98-9ad5-f167b88ddffc,
2025-11-04 08:06:13.322365+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d1-7b98-9ad5-f167b88ddffc,Finished in state Completed()
2025-11-04 08:07:22.415090+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d5-730d-9db2-e515319e5312,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '45s', 'node': 'a40-102', 'gpus': '1', 'ports': ''}"
2025-11-04 08:08:28.396713+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d5-730d-9db2-e515319e5312,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '1m', 'node': 'a40-102', 'gpus': '1', 'ports': ''}"
2025-11-04 08:09:35.827023+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d5-730d-9db2-e515319e5312,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '2m', 'node': 'a40-102', 'gpus': '1', 'ports': ''}"
2025-11-04 08:10:43.600857+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d5-730d-9db2-e515319e5312,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '4m', 'node': 'a40-102', 'gpus': '1', 'ports': ''}"
2025-11-04 08:11:45.398282+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d5-730d-9db2-e515319e5312,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '5m', 'node': 'a40-102', 'gpus': '1', 'ports': ''}"
2025-11-04 08:12:52.477268+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d5-730d-9db2-e515319e5312,"{'user': 'dlk-bot', 'status': 'Running', 'reason': '', 'age': '6m', 'node': 'a40-102', 'gpus': '1', 'ports': ''}"
2025-11-04 08:13:13.079127+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d6-7af3-94ed-f921ac0b9aa5,None
2025-11-04 08:13:13.083977+00:00,40,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d6-7af3-94ed-f921ac0b9aa5,Inference was failed. See the logs for detail.
2025-11-04 08:13:13.086092+00:00,40,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d6-7af3-94ed-f921ac0b9aa5,"Task run failed with exception: InferenceFailError() - No retries configured for this task.
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 857, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 1487, in run_task_sync
    engine.call_task_fn(txn)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 874, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 135, in run_check_inference_status_redis
    raise InferenceFailError
modint_prefect.configs.InferenceFailError"
2025-11-04 08:13:13.100510+00:00,40,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d6-7af3-94ed-f921ac0b9aa5,Finished in state Failed('Task run encountered an exception InferenceFailError: ')
2025-11-04 08:14:00.252061+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d5-730d-9db2-e515319e5312,Scheduler status succeeded!
2025-11-04 08:14:00.254244+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d5-730d-9db2-e515319e5312,"{'user': 'dlk-bot', 'status': 'Succeeded', 'reason': 'Completed', 'age': '7m', 'node': 'a40-102', 'gpus': '', 'ports': ''}"
2025-11-04 08:14:00.256151+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d5-730d-9db2-e515319e5312,"['/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers', '  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)', '\rDownloading artifacts:   0%|          | 0/2 [00:00<?, ?it/s]\rDownloading artifacts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 40.90it/s]\rDownloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.04s/it]\rDownloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.04s/it]\rDownloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.04s/it]', 'load checkpoint from local path: /tmp/tmpyidylck9/checkpoint/model_final.pth', 'The model and loaded state dict do not match exactly', '', 'unexpected key in source state_dict: perceptual_loss.vgg.mean, perceptual_loss.vgg.std, perceptual_loss.vgg.vgg_layers.0.weight, perceptual_loss.vgg.vgg_layers.0.bias, perceptual_loss.vgg.vgg_layers.2.weight, perceptual_loss.vgg.vgg_layers.2.bias, perceptual_loss.vgg.vgg_layers.5.weight, perceptual_loss.vgg.vgg_layers.5.bias, perceptual_loss.vgg.vgg_layers.7.weight, perceptual_loss.vgg.vgg_layers.7.bias, perceptual_loss.vgg.vgg_layers.10.weight, perceptual_loss.vgg.vgg_layers.10.bias, perceptual_loss.vgg.vgg_layers.12.weight, perceptual_loss.vgg.vgg_layers.12.bias, perceptual_loss.vgg.vgg_layers.14.weight, perceptual_loss.vgg.vgg_layers.14.bias, perceptual_loss.vgg.vgg_layers.16.weight, perceptual_loss.vgg.vgg_layers.16.bias, perceptual_loss.vgg.vgg_layers.19.weight, perceptual_loss.vgg.vgg_layers.19.bias, perceptual_loss.vgg.vgg_layers.21.weight, perceptual_loss.vgg.vgg_layers.21.bias, perceptual_loss.vgg.vgg_layers.23.weight, perceptual_loss.vgg.vgg_layers.23.bias, perceptual_loss.vgg.vgg_layers.25.weight, perceptual_loss.vgg.vgg_layers.25.bias, perceptual_loss.vgg.vgg_layers.28.weight, perceptual_loss.vgg.vgg_layers.28.bias, perceptual_loss.vgg.vgg_layers.30.weight, perceptual_loss.vgg.vgg_layers.30.bias, perceptual_loss.vgg.vgg_layers.32.weight, perceptual_loss.vgg.vgg_layers.32.bias, perceptual_loss.vgg.vgg_layers.34.weight, perceptual_loss.vgg.vgg_layers.34.bias', '', '/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers', '  warnings.warn(f""Importing from {__name__} is deprecated, please import via timm.layers"", FutureWarning)', '/usr/local/lib/python3.10/dist-packages/mmedit/utils/setup_env.py:17: UserWarning: Multi-processing start method `fork` is different from the previous setting `spawn`.It will be force set to `fork`. You can change this behavior by changing `mp_start_method` in your config.', '  warnings.warn(', '[2025-11-04 08:12:56] [INFO] [SE Runner - 0] - start load ddp model', 'load checkpoint from local path: /tmp/tmpyidylck9/checkpoint/model_final.pth', 'The model and loaded state dict do not match exactly', '', 'unexpected key in source state_dict: perceptual_loss.vgg.mean, perceptual_loss.vgg.std, perceptual_loss.vgg.vgg_layers.0.weight, perceptual_loss.vgg.vgg_layers.0.bias, perceptual_loss.vgg.vgg_layers.2.weight, perceptual_loss.vgg.vgg_layers.2.bias, perceptual_loss.vgg.vgg_layers.5.weight, perceptual_loss.vgg.vgg_layers.5.bias, perceptual_loss.vgg.vgg_layers.7.weight, perceptual_loss.vgg.vgg_layers.7.bias, perceptual_loss.vgg.vgg_layers.10.weight, perceptual_loss.vgg.vgg_layers.10.bias, perceptual_loss.vgg.vgg_layers.12.weight, perceptual_loss.vgg.vgg_layers.12.bias, perceptual_loss.vgg.vgg_layers.14.weight, perceptual_loss.vgg.vgg_layers.14.bias, perceptual_loss.vgg.vgg_layers.16.weight, perceptual_loss.vgg.vgg_layers.16.bias, perceptual_loss.vgg.vgg_layers.19.weight, perceptual_loss.vgg.vgg_layers.19.bias, perceptual_loss.vgg.vgg_layers.21.weight, perceptual_loss.vgg.vgg_layers.21.bias, perceptual_loss.vgg.vgg_layers.23.weight, perceptual_loss.vgg.vgg_layers.23.bias, perceptual_loss.vgg.vgg_layers.25.weight, perceptual_loss.vgg.vgg_layers.25.bias, perceptual_loss.vgg.vgg_layers.28.weight, perceptual_loss.vgg.vgg_layers.28.bias, perceptual_loss.vgg.vgg_layers.30.weight, perceptual_loss.vgg.vgg_layers.30.bias, perceptual_loss.vgg.vgg_layers.32.weight, perceptual_loss.vgg.vgg_layers.32.bias, perceptual_loss.vgg.vgg_layers.34.weight, perceptual_loss.vgg.vgg_layers.34.bias', '', '[2025-11-04 08:12:58] [INFO] [SE Runner - 0] - end load ddp model', '[2025-11-04 08:12:58] [INFO] [SE Runner - 0] - start build dataloader', '[2025-11-04 08:13:00] [INFO] [SE Runner - 0] - end build dataloader', '[2025-11-04 08:13:00] [INFO] [SE Runner - 0] - start create memory map', '[2025-11-04 08:13:00] [INFO] [SE Runner - 0] - end create memory map', '2025-11-04 08:13:02.003 | ERROR    | se:inference:434 - An exception occurred:', 'Traceback (most recent call last):', '  File ""/weaver/se.py"", line 397, in inference', '    mp.spawn(', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 246, in spawn', '    return start_processes(fn, args, nprocs, join, daemon, start_method=""spawn"")', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 202, in start_processes', '    while not context.join():', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 163, in join', '    raise ProcessRaisedException(msg, error_index, failed_process.pid)', 'torch.multiprocessing.spawn.ProcessRaisedException: ', '', '-- Process 0 terminated with the following error:', 'Traceback (most recent call last):', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 74, in _wrap', '    fn(i, *args)', '  File ""/weaver/se.py"", line 329, in mp_inference', '    results = self.predict(data, model)', '  File ""/weaver/se.py"", line 154, in predict', '    result = model(**batch, test_mode=True)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py"", line 1519, in forward', '    else self._run_ddp_forward(*inputs, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py"", line 1355, in _run_ddp_forward', '    return self.module(*inputs, **kwargs)  # type: ignore[index]', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/selfsup/module/mmcv/mmcv/runner/fp16_utils.py"", line 109, in new_func', '    return old_func(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/mmedit/models/restorers/srgan.py"", line 95, in forward', '    return self.forward_test(lq, gt, **kwargs)', '  File ""/weaver/weaver/models/restorers/real_esrgan.py"", line 275, in forward_test', '    output = _model(lq)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/weaver/weaver/models/backbones/sr_backbones/restormer_net.py"", line 468, in forward', '    inp_enc_level1 = self.patch_embed(inp_img)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/weaver/weaver/models/backbones/sr_backbones/restormer_net.py"", line 241, in forward', '    x = self.proj(x)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py"", line 460, in forward', '    return self._conv_forward(input, self.weight, self.bias)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py"", line 456, in _conv_forward', '    return F.conv2d(input, weight, bias, self.stride,', 'RuntimeError: Given groups=1, weight of size [64, 4, 3, 3], expected input[1, 3, 1000, 1000] to have 4 channels, but got 3 channels instead', '', '', '[                                                  ] 0/12, elapsed: 0s, ETA:\x1b[32m2025-11-04T08:13:02.003054+0000\x1b[0m \x1b[31m\x1b[1mAn exception occurred:', 'Traceback (most recent call last):', '  File ""/weaver/se.py"", line 397, in inference', '    mp.spawn(', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 246, in spawn', '    return start_processes(fn, args, nprocs, join, daemon, start_method=""spawn"")', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 202, in start_processes', '    while not context.join():', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 163, in join', '    raise ProcessRaisedException(msg, error_index, failed_process.pid)', 'torch.multiprocessing.spawn.ProcessRaisedException: ', '', '-- Process 0 terminated with the following error:', 'Traceback (most recent call last):', '  File ""/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py"", line 74, in _wrap', '    fn(i, *args)', '  File ""/weaver/se.py"", line 329, in mp_inference', '    results = self.predict(data, model)', '  File ""/weaver/se.py"", line 154, in predict', '    result = model(**batch, test_mode=True)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py"", line 1519, in forward', '    else self._run_ddp_forward(*inputs, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py"", line 1355, in _run_ddp_forward', '    return self.module(*inputs, **kwargs)  # type: ignore[index]', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/selfsup/module/mmcv/mmcv/runner/fp16_utils.py"", line 109, in new_func', '    return old_func(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/mmedit/models/restorers/srgan.py"", line 95, in forward', '    return self.forward_test(lq, gt, **kwargs)', '  File ""/weaver/weaver/models/restorers/real_esrgan.py"", line 275, in forward_test', '    output = _model(lq)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/weaver/weaver/models/backbones/sr_backbones/restormer_net.py"", line 468, in forward', '    inp_enc_level1 = self.patch_embed(inp_img)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/weaver/weaver/models/backbones/sr_backbones/restormer_net.py"", line 241, in forward', '    x = self.proj(x)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl', '    return self._call_impl(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py"", line 1527, in _call_impl', '    return forward_call(*args, **kwargs)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py"", line 460, in forward', '    return self._conv_forward(input, self.weight, self.bias)', '  File ""/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py"", line 456, in _conv_forward', '    return F.conv2d(input, weight, bias, self.stride,', 'RuntimeError: Given groups=1, weight of size [64, 4, 3, 3], expected input[1, 3, 1000, 1000] to have 4 channels, but got 3 channels instead', '', '\x1b[0m', '']"
2025-11-04 08:14:00.278315+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,019a4de6-f1d5-730d-9db2-e515319e5312,Finished in state Completed()
2025-11-04 08:14:00.289178+00:00,40,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,,"Encountered exception during execution: InferenceFailError()
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 782, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 1397, in run_flow_sync
    engine.call_flow_fn()
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 802, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 528, in run_modint_flow
    inference_result = check_inference_status_future.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/futures.py"", line 222, in result
    _result = self._final_state.result(
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/compatibility/async_dispatch.py"", line 94, in wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/prefect/client/schemas/objects.py"", line 366, in result
    return run_coro_as_sync(
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 207, in run_coro_as_sync
    return call.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 365, in result
    return self.future.result(timeout=timeout)
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 192, in result
    return self.__get_result()
  File ""/usr/local/lib/python3.10/concurrent/futures/_base.py"", line 403, in __get_result
    raise self._exception
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 441, in _run_async
    result = await coro
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 188, in coroutine_wrapper
    return await task
  File ""/usr/local/lib/python3.10/site-packages/prefect/states.py"", line 85, in get_state_result
    return await _get_state_result(
  File ""/usr/local/lib/python3.10/site-packages/prefect/states.py"", line 157, in _get_state_result
    raise await get_state_exception(state)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 857, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 1487, in run_task_sync
    engine.call_task_fn(txn)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 874, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 135, in run_check_inference_status_redis
    raise InferenceFailError
modint_prefect.configs.InferenceFailError"
2025-11-04 08:14:00.391554+00:00,20,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,,Finished in state Failed('Flow run encountered an exception: InferenceFailError: ')
2025-11-04 08:14:00.394308+00:00,40,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,,"Engine execution exited with unexpected exception
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 1554, in run_flow
    ret_val = run_flow_sync(**kwargs)
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 1399, in run_flow_sync
    return engine.state if return_type == ""state"" else engine.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 361, in result
    raise self._raised
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 782, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 1397, in run_flow_sync
    engine.call_flow_fn()
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 802, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 528, in run_modint_flow
    inference_result = check_inference_status_future.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/futures.py"", line 222, in result
    _result = self._final_state.result(
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/compatibility/async_dispatch.py"", line 94, in wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/prefect/client/schemas/objects.py"", line 366, in result
    return run_coro_as_sync(
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 207, in run_coro_as_sync
    return call.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 365, in result
    return self.future.result(timeout=timeout)
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 192, in result
    return self.__get_result()
  File ""/usr/local/lib/python3.10/concurrent/futures/_base.py"", line 403, in __get_result
    raise self._exception
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 441, in _run_async
    result = await coro
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 188, in coroutine_wrapper
    return await task
  File ""/usr/local/lib/python3.10/site-packages/prefect/states.py"", line 85, in get_state_result
    return await _get_state_result(
  File ""/usr/local/lib/python3.10/site-packages/prefect/states.py"", line 157, in _get_state_result
    raise await get_state_exception(state)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 857, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 1487, in run_task_sync
    engine.call_task_fn(txn)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 874, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 135, in run_check_inference_status_redis
    raise InferenceFailError
modint_prefect.configs.InferenceFailError"
2025-11-04 08:14:01.044327+00:00,40,924a1cd4-7c15-4f85-9a39-c5b0652f03dc,,Process for flow run 'phi2-betazed-nebula' exited with status code: 1
