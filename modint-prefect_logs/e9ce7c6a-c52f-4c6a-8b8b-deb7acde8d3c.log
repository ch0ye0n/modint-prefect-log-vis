timestamp,level,flow_run_id,task_run_id,message
2025-11-12 04:54:00.550812+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,,Worker 'KubernetesWorker b5700100-6765-494e-b637-58b56901dc89' submitting flow run 'e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c'
2025-11-12 04:54:00.734607+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,,Creating Kubernetes job...
2025-11-12 04:54:00.943296+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,,Completed submission of flow run 'e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c'
2025-11-12 04:54:07.354013+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,,Opening process...
2025-11-12 04:54:10.150044+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,, > Running git_clone step...
2025-11-12 04:54:15.622331+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,,Beginning flow run 'free-lemming' for flow 'run-modint-flow'
2025-11-12 04:54:15.801654+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1768-7e34-b0ab-48b408457aab,This job ID will be used - modint-prefect-free-lemming-1
2025-11-12 04:54:15.806568+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1768-7e34-b0ab-48b408457aab,Finished in state Completed()
2025-11-12 04:54:16.447909+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-7f96-82e7-e39074af1c07,Finished in state Completed()
2025-11-12 04:54:16.505099+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1822-7675-a8be-0d29168162aa,{'scene_path': '/nas/COG/planet/Y2025/M11/D07/planet_20251107_062524_ssc8_u0001/20251107_062524_ssc8_u0001_pansharpened_clip_cog.tif'}
2025-11-12 04:54:16.600200+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1af6-7725-be8f-ec328974a9c3,Finished in state Completed()
2025-11-12 04:54:17.642371+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,Beginning subflow run 'practical-tarantula' for flow 'run-namespaced-job'
2025-11-12 04:54:52.559387+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"Loads checkpoint by local backend from path: /tmp/tmpbdlevmtk/checkpoint/model_final.pth
"
2025-11-12 04:54:52.561891+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]Downloading artifacts:  14%|â–ˆâ–        | 1/7 [00:00<00:00, 4894.17it/s]Downloading artifacts:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:00, 289.62it/s] Downloading artifacts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:00<00:00, 353.71it/s]Downloading artifacts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:00<00:00, 157.30it/s]Downloading artifacts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:00<00:00, 79.40it/s] Downloading artifacts:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:00<00:00, 71.05it/s]Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:04<00:00,  1.41it/s]Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:04<00:00,  1.41it/s]Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:04<00:00,  1.41it/s]
"
2025-11-12 04:54:54.523123+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"Making patches:   0%|          | 0/1 [00:00<?, ?it/s]Making patches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 5660.33it/s]
"
2025-11-12 04:54:55.601680+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"/usr/local/lib/python3.8/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=linear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
"
2025-11-12 04:54:55.604163+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  warnings.warn(
"
2025-11-12 04:54:55.606089+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"2025-11-12 04:54:55.600 | ERROR    | modint.runner.base_runner:inference:137 - An exception occurred:
"
2025-11-12 04:54:55.608458+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"Traceback (most recent call last):
"
2025-11-12 04:54:55.610792+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/modint/runner/base_runner.py"", line 121, in inference
"
2025-11-12 04:54:55.612944+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    result = self.predict(data)
"
2025-11-12 04:54:55.614880+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/torch/autograd/grad_mode.py"", line 28, in decorate_context
"
2025-11-12 04:54:55.616518+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return func(*args, **kwargs)
"
2025-11-12 04:54:55.618375+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/ardet/ardet/apis/det_runner.py"", line 99, in predict
"
2025-11-12 04:54:55.620179+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return self.model.test_step(batch)
"
2025-11-12 04:54:55.621829+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py"", line 145, in test_step
"
2025-11-12 04:54:55.623773+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return self._run_forward(data, mode='predict')  # type: ignore
"
2025-11-12 04:54:55.625387+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py"", line 361, in _run_forward
"
2025-11-12 04:54:55.626754+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    results = self(**data, mode=mode)
"
2025-11-12 04:54:55.628357+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1051, in _call_impl
"
2025-11-12 04:54:55.629824+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return forward_call(*input, **kwargs)
"
2025-11-12 04:54:55.631159+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/mmdet/models/detectors/base.py"", line 94, in forward
"
2025-11-12 04:54:55.632787+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return self.predict(inputs, data_samples)
"
2025-11-12 04:54:55.634446+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/mmdet/models/detectors/two_stage.py"", line 227, in predict
"
2025-11-12 04:54:55.641716+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    x = self.extract_feat(batch_inputs)
"
2025-11-12 04:54:55.643132+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/mmdet/models/detectors/two_stage.py"", line 110, in extract_feat
"
2025-11-12 04:54:55.644678+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    x = self.backbone(batch_inputs)
"
2025-11-12 04:54:55.646160+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1051, in _call_impl
"
2025-11-12 04:54:55.647936+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return forward_call(*input, **kwargs)
"
2025-11-12 04:54:55.649641+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/ardet/ardet/models/backbones/vitdet.py"", line 423, in forward
"
2025-11-12 04:54:55.651135+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    x = blk(x)
"
2025-11-12 04:54:55.652874+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1051, in _call_impl
"
2025-11-12 04:54:55.654570+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return forward_call(*input, **kwargs)
"
2025-11-12 04:54:55.655925+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/ardet/ardet/models/backbones/vitdet.py"", line 303, in forward
"
2025-11-12 04:54:55.657523+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    x = self.attn(x)
"
2025-11-12 04:54:55.659059+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1051, in _call_impl
"
2025-11-12 04:54:55.660451+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return forward_call(*input, **kwargs)
"
2025-11-12 04:54:55.662062+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/ardet/ardet/models/backbones/vitdet.py"", line 209, in forward
"
2025-11-12 04:54:55.663613+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    attn = add_decomposed_rel_pos(attn, q, self.rel_pos_h,
"
2025-11-12 04:54:55.664923+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/ardet/ardet/models/backbones/vitdet.py"", line 166, in add_decomposed_rel_pos
"
2025-11-12 04:54:55.666379+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    attn.view(B, q_h, q_w, k_h, k_w) +  # noqa: W504
"
2025-11-12 04:54:55.667788+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"RuntimeError: CUDA out of memory. Tried to allocate 4.47 GiB (GPU 0; 10.57 GiB total capacity; 5.19 GiB already allocated; 4.01 GiB free; 5.27 GiB reserved in total by PyTorch)
"
2025-11-12 04:54:55.669069+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"
"
2025-11-12 04:54:55.670469+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"[32m2025-11-12T04:54:55.600188+0000[0m [31m[1mAn exception occurred:
"
2025-11-12 04:54:55.671889+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"Traceback (most recent call last):
"
2025-11-12 04:54:55.673060+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/modint/runner/base_runner.py"", line 121, in inference
"
2025-11-12 04:54:55.674527+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    result = self.predict(data)
"
2025-11-12 04:54:55.675811+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/torch/autograd/grad_mode.py"", line 28, in decorate_context
"
2025-11-12 04:54:55.676879+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return func(*args, **kwargs)
"
2025-11-12 04:54:55.678638+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/ardet/ardet/apis/det_runner.py"", line 99, in predict
"
2025-11-12 04:54:55.679666+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return self.model.test_step(batch)
"
2025-11-12 04:54:55.680927+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py"", line 145, in test_step
"
2025-11-12 04:54:55.682212+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return self._run_forward(data, mode='predict')  # type: ignore
"
2025-11-12 04:54:55.685458+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py"", line 361, in _run_forward
"
2025-11-12 04:54:55.686255+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    results = self(**data, mode=mode)
"
2025-11-12 04:54:55.687003+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1051, in _call_impl
"
2025-11-12 04:54:55.687770+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return forward_call(*input, **kwargs)
"
2025-11-12 04:54:55.688514+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/mmdet/models/detectors/base.py"", line 94, in forward
"
2025-11-12 04:54:55.689262+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return self.predict(inputs, data_samples)
"
2025-11-12 04:54:55.689998+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/mmdet/models/detectors/two_stage.py"", line 227, in predict
"
2025-11-12 04:54:55.690749+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    x = self.extract_feat(batch_inputs)
"
2025-11-12 04:54:55.691482+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/mmdet/models/detectors/two_stage.py"", line 110, in extract_feat
"
2025-11-12 04:54:55.692251+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    x = self.backbone(batch_inputs)
"
2025-11-12 04:54:55.692987+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1051, in _call_impl
"
2025-11-12 04:54:55.693734+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return forward_call(*input, **kwargs)
"
2025-11-12 04:54:55.694417+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/ardet/ardet/models/backbones/vitdet.py"", line 423, in forward
"
2025-11-12 04:54:55.695029+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    x = blk(x)
"
2025-11-12 04:54:55.695934+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1051, in _call_impl
"
2025-11-12 04:54:55.697083+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return forward_call(*input, **kwargs)
"
2025-11-12 04:54:55.741347+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/ardet/ardet/models/backbones/vitdet.py"", line 303, in forward
"
2025-11-12 04:54:55.743185+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    x = self.attn(x)
"
2025-11-12 04:54:55.745291+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1051, in _call_impl
"
2025-11-12 04:54:55.747635+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    return forward_call(*input, **kwargs)
"
2025-11-12 04:54:55.749784+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/ardet/ardet/models/backbones/vitdet.py"", line 209, in forward
"
2025-11-12 04:54:55.752110+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    attn = add_decomposed_rel_pos(attn, q, self.rel_pos_h,
"
2025-11-12 04:54:55.754238+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"  File ""/ardet/ardet/models/backbones/vitdet.py"", line 166, in add_decomposed_rel_pos
"
2025-11-12 04:54:55.757108+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"    attn.view(B, q_h, q_w, k_h, k_w) +  # noqa: W504
"
2025-11-12 04:54:55.759067+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"RuntimeError: CUDA out of memory. Tried to allocate 4.47 GiB (GPU 0; 10.57 GiB total capacity; 5.19 GiB already allocated; 4.01 GiB free; 5.27 GiB reserved in total by PyTorch)
"
2025-11-12 04:54:55.760947+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,"[0m
"
2025-11-12 04:55:06.863553+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1801-78e5-bbad-15badf3ee0e1,Finished in state Completed()
2025-11-12 04:55:16.549134+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1822-7675-a8be-0d29168162aa,"{'msg': 'Traceback (most recent call last):\n  File ""/usr/local/lib/python3.8/site-packages/modint/runner/base_runner.py"", line 121, in inference\n    result = self.predict(data)\n  File ""/usr/local/lib/python3.8/site-packages/torch/autograd/grad_mode.py"", line 28, in decorate_context\n    return func(*args, **kwargs)\n  File ""/ardet/ardet/apis/det_runner.py"", line 99, in predict\n    return self.model.test_step(batch)\n  File ""/usr/local/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py"", line 145, in test_step\n    return self._run_forward(data, mode=\'predict\')  # type: ignore\n  File ""/usr/local/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py"", line 361, in _run_forward\n    results = self(**data, mode=mode)\n  File ""/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File ""/usr/local/lib/python3.8/site-packages/mmdet/models/detectors/base.py"", line 94, in forward\n    return self.predict(inputs, data_samples)\n  File ""/usr/local/lib/python3.8/site-packages/mmdet/models/detectors/two_stage.py"", line 227, in predict\n    x = self.extract_feat(batch_inputs)\n  File ""/usr/local/lib/python3.8/site-packages/mmdet/models/detectors/two_stage.py"", line 110, in extract_feat\n    x = self.backbone(batch_inputs)\n  File ""/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File ""/ardet/ardet/models/backbones/vitdet.py"", line 423, in forward\n    x = blk(x)\n  File ""/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File ""/ardet/ardet/models/backbones/vitdet.py"", line 303, in forward\n    x = self.attn(x)\n  File ""/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File ""/ardet/ardet/models/backbones/vitdet.py"", line 209, in forward\n    attn = add_decomposed_rel_pos(attn, q, self.rel_pos_h,\n  File ""/ardet/ardet/models/backbones/vitdet.py"", line 166, in add_decomposed_rel_pos\n    attn.view(B, q_h, q_w, k_h, k_w) +  # noqa: W504\nRuntimeError: CUDA out of memory. Tried to allocate 4.47 GiB (GPU 0; 10.57 GiB total capacity; 5.19 GiB already allocated; 4.01 GiB free; 5.27 GiB reserved in total by PyTorch)\n', 'retriable': False}"
2025-11-12 04:55:16.555835+00:00,40,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1822-7675-a8be-0d29168162aa,Inference was failed. See the logs for detail.
2025-11-12 04:55:16.557910+00:00,40,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1822-7675-a8be-0d29168162aa,"Task run failed with exception: InferenceFailError() - No retries configured for this task.
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 857, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 1487, in run_task_sync
    engine.call_task_fn(txn)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 874, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 134, in run_check_inference_status_redis
    raise InferenceFailError
modint_prefect.configs.InferenceFailError"
2025-11-12 04:55:16.572493+00:00,40,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,019a766a-1822-7675-a8be-0d29168162aa,Finished in state Failed('Task run encountered an exception InferenceFailError: ')
2025-11-12 04:55:16.582165+00:00,40,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,,"Encountered exception during execution: InferenceFailError()
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 782, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 1397, in run_flow_sync
    engine.call_flow_fn()
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 802, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 518, in run_modint_flow
    inference_result = check_inference_status_future.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/futures.py"", line 222, in result
    _result = self._final_state.result(
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/compatibility/async_dispatch.py"", line 94, in wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/prefect/client/schemas/objects.py"", line 366, in result
    return run_coro_as_sync(
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 207, in run_coro_as_sync
    return call.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 365, in result
    return self.future.result(timeout=timeout)
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 192, in result
    return self.__get_result()
  File ""/usr/local/lib/python3.10/concurrent/futures/_base.py"", line 403, in __get_result
    raise self._exception
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 441, in _run_async
    result = await coro
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 188, in coroutine_wrapper
    return await task
  File ""/usr/local/lib/python3.10/site-packages/prefect/states.py"", line 85, in get_state_result
    return await _get_state_result(
  File ""/usr/local/lib/python3.10/site-packages/prefect/states.py"", line 157, in _get_state_result
    raise await get_state_exception(state)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 857, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 1487, in run_task_sync
    engine.call_task_fn(txn)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 874, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 134, in run_check_inference_status_redis
    raise InferenceFailError
modint_prefect.configs.InferenceFailError"
2025-11-12 04:55:16.638448+00:00,20,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,,Finished in state Failed('Flow run encountered an exception: InferenceFailError: ')
2025-11-12 04:55:16.641084+00:00,40,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,,"Engine execution exited with unexpected exception
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 1554, in run_flow
    ret_val = run_flow_sync(**kwargs)
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 1399, in run_flow_sync
    return engine.state if return_type == ""state"" else engine.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 361, in result
    raise self._raised
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 782, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 1397, in run_flow_sync
    engine.call_flow_fn()
  File ""/usr/local/lib/python3.10/site-packages/prefect/flow_engine.py"", line 802, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 518, in run_modint_flow
    inference_result = check_inference_status_future.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/futures.py"", line 222, in result
    _result = self._final_state.result(
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/compatibility/async_dispatch.py"", line 94, in wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/prefect/client/schemas/objects.py"", line 366, in result
    return run_coro_as_sync(
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 207, in run_coro_as_sync
    return call.result()
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 365, in result
    return self.future.result(timeout=timeout)
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 192, in result
    return self.__get_result()
  File ""/usr/local/lib/python3.10/concurrent/futures/_base.py"", line 403, in __get_result
    raise self._exception
  File ""/usr/local/lib/python3.10/site-packages/prefect/_internal/concurrency/calls.py"", line 441, in _run_async
    result = await coro
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/asyncutils.py"", line 188, in coroutine_wrapper
    return await task
  File ""/usr/local/lib/python3.10/site-packages/prefect/states.py"", line 85, in get_state_result
    return await _get_state_result(
  File ""/usr/local/lib/python3.10/site-packages/prefect/states.py"", line 157, in _get_state_result
    raise await get_state_exception(state)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 857, in run_context
    yield self
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 1487, in run_task_sync
    engine.call_task_fn(txn)
  File ""/usr/local/lib/python3.10/site-packages/prefect/task_engine.py"", line 874, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
  File ""/usr/local/lib/python3.10/site-packages/prefect/utilities/callables.py"", line 210, in call_with_parameters
    return fn(*args, **kwargs)
  File ""/app/modint-prefect-main/modint_prefect/prefect_flow.py"", line 134, in run_check_inference_status_redis
    raise InferenceFailError
modint_prefect.configs.InferenceFailError"
2025-11-12 04:55:17.286862+00:00,40,e9ce7c6a-c52f-4c6a-8b8b-deb7acde8d3c,,Process for flow run 'free-lemming' exited with status code: 1
